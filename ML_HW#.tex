\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\newcommand{\eqn}{\[
    \stcomp{(A \cup B)} = \stcomp{A} \cap \stcomp{B}
\]}
\usepackage{bbm}
\usepackage{amsfonts}
\usepackage{graphicx}%بسته‌ای برای اضافه کردن عکس
\usepackage{float}
\usepackage[colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{geometry}
\usepackage {tikz}
\usepackage{color}
\usepackage{amssymb}
\usepackage{enumitem}
\setlist[enumerate,1]{label=(\alph*) , itemsep=8pt,topsep=8pt}
\setlist[enumerate,2]{label=\arabic*. ,itemsep=10pt,topsep=10pt}
\setlist[enumerate,3]{label=\alph*. ,itemsep=10pt,topsep=10pt}
\usepackage{xepersian}
\settextfont[ExternalLocation=Niloofar/,
ItalicFont = XB-NiloofarIt.ttf,
BoldFont = XB-NiloofarBd.ttf,
BoldItalicFont = XB-NiloofarBdIt.ttf
]{XB-Niloofar.ttf}


%\underset{x}{\operatorname{argmax}} 
\DeclareMathOperator*{\argmin}{arg\,min}	
 
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=15mm,
 }
%دستور زیر برای تعیین فونت متن فارسی می‌باشد.

%\settextfont[Scale=1]{XB Niloofar}%{Yas}
%\setlength{\parindent}{0pt}

\newcounter{probcnt}

\NewDocumentCommand{\problem}{m}{
\stepcounter{probcnt}\bigskip\medskip{\underline{\textbf{
 	 سوال
   \arabic{probcnt}:
   #1
}}}
\nopagebreak\par\medskip
\vspace{1mm}
}

\newcommand{\heading}[4]{
\parindent=0em

\rightline{
\makebox[6em][c]{
\includegraphics[height=1.6cm]{images/logo}
}}
\vspace{-.5em}
{\scriptsize\bf دانشکده‌ی مهندسی کامپیوتر}
\hfill {\small
مدرس: دکتر مهدیه سلیمانی \ 
}\\[-5.3em]
\leftline{\hfill\Large\bf 
مفاهیم پیشرفته در یادگیری ماشین
}\\[.8em]
\leftline{\hfill\bf 
نیم‌سال دوم 401-1400
}\\[1.5em]
\hrule height .12em
\normalsize
\vspace{0.2em} 
\makebox[5cm][r]{#1}
\hfill 
\makebox[5cm][c]{\large #2} 
\hfill
\makebox[5cm][l]{\small #3 #4}
\vspace{1mm} 
\hrule height .1em
}

\newcommand{\hwhead}[3]{\heading{#1}{#2}{زمان تحویل:}{#3}}
\DeclareMathOperator{\Wp}{\hat{W}^{(0)}}
\DeclareMathOperator{\Wh}{\hat{W}}
\DeclareMathOperator{\Lossh}{\hat{\mathcal{L}}}
\DeclareMathOperator{\Loss}{\mathcal{L}}
\DeclareMathOperator{\Alg}{\mathcal{A}lg}
\DeclareMathOperator{\T}{\mathcal{T}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\grad}{\nabla}

\begin{document}
 
\vspace{2mm}

\centerline{ به نام خدا}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ویرایش ددلاین و شماره و عنوان تمرین %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\hwhead{تمرین سری دوم}{عنوان تمرین}{۲۵ اسفندماه}

 \vspace{0.5cm}
لطفا نکات زیر را رعایت کنید:
\begin{itemize}
\item[-]
سوالات خود را از طریق پست مربوط به تمرین در \lr{Quera} مطرح کنید.
\item[-]
در هر کدام از سوالات، اگر از منابع خاصی استفاده کرده‌اید باید آن را ذکر کنید.
\item[-] 
 پاسخ ارسالی واضح و خوانا باشد.

\item[-]
تمام پاسخ‌های خود را در یک فایل با فرمت \lr{HW\#\_[SID]\_[Fullname].zip} روی کوئرا قرار دهید.
\item[-]
برای ارسال هر تمرین تا ساعت ۲۳:۵۹ روز ددلاین فرصت دارید. علاوه بر آن، در هر تمرین می توانید تا سقف هفت روز از تأخیر مجاز باقیمانده‌ی خود استفاده کنید.

\item[-]
برای کسب نمره کامل در این تمرین کافیست 160 نمره را دریافت نمایید، ما بقی نمرات امتیازی می باشند (40 نمره امتیازی).
\end{itemize}

\hrule height .1em

\problem{متا-یادگیری مبتنی بر بهینه‌سازی دو سطحی}
همانطور که در جلسات درس مشاهده کرده‌اید، یکی از روش‌های متا-یادگیری، خانواده بهینه‌سازی دو سطحی بوده که مهمترین کار در این زمینه روش MAML می‌باشد. در این خانواده از روش‌ها، متا-پارامترها (پارامترهای آهسته) هم بعد با پارامترهای مختص وظیفه (پارامترهای سریع) بوده و به عنوان یک نقطه شروع برای آن‌ها عمل می‌کنند. به طور دقیق‌تر، اگر توزیع وظایف (Tasks) را به صورت 
$p(\T)$
در نظر بگیریم، می‌توان رابطه زیر را برای یادگیری متا-پارامترها ارائه داد:

\begin{subequations}
	\begin{alignat}{2}
		\theta^* = \argmin_{\theta} \E_{\T = (S, Q) \sim p(\T)} [\Loss (\phi, Q)]\\
		Where \quad \phi = \Alg(\theta, S)
		 \label{eq:0}
	\end{alignat}
\end{subequations}

که در این رابطه 
$S$
مجموعه داده‌های پتشیبان (Support) و 
$Q$
مجموعه داده‌های پرسمان (Query) مربوط به هر وظیفه (Task) را نشان می‌دهد. در این رابطه، محاسبه پارامترهای سریع $\phi$ توسط روش 
$\Alg$
انجام می‌شود که در مقالات مربوطه به طرق مختلفی انتخاب شده و بهینه‌سازی داخلی 
(
\lr{Inner-Level}
) نامیده می‌شود. همچنین در رابطه فوق، بهینه‌سازی خارجی 
(\lr{Outer-Level})
که روی پارامترهای $\theta$ صورت می‌پذیرد، به شکل 
$\argmin$
نمایش داده شده است. 

برای انجام بهینه‌سازی خارجی، لازم است تا از تابع معرفی شده نسبت به 
$\theta$
گرادیان را به صورت زیر محاسبه کرده و $\theta$ را از طریق آن به‌روزرسانی نماییم:

\begin{equation} \label{eq:1}
		\nabla_{\theta} \E [\Loss (\phi, Q)] = 
		\E [\nabla_{\theta} \Loss (\Alg(\theta, S), Q)]
\end{equation}

برای محاسبه عبارت فوق، از قاعده زنجیره‌ای مشتق استفاده می‌کنیم:

\begin{equation}		\label{eq:2}
		\nabla_{\theta} \Loss (\Alg(\theta, S), Q) 		= \nabla_{\phi} \Loss (\phi, Q) |_{\phi = \Alg(\theta, S)} 
		\times \frac{d}{d\theta}\Alg(\theta, S)
\end{equation}

همانطور که مشاهده می‌کنید، رابطه فوق از دو جمله تشکیل شده است؛ محاسبه جمله اول نسبتاً راحت است. چرا که کافیست تا از 
$\Loss$
مشتق گرفته و مقدار 
$\Alg(\theta, S)$
را در آن جایگذاری کنیم و در این صورت گرادیانی از 
$\Alg(\theta, S)$
عبور نمی‌کند. این در حالیست که برای محاسبه جمله دوم، لازم است تا عملیات مشتق‌گیری را از داخل الگوریتم $\Alg(\theta, S)$ عبور دهیم. این مسئله می‌تواند مشکل‌زا باشد چرا که ممکن است $\Alg(\theta, S)$ اصلاً قابلیت عبور گرادیان را نداشته باشد یا اگر دارد ممکن است منجر به محاسبات پرهزینه شود. به عنوان مثال، در روش MAML داریم:

\begin{equation}		\label{eq:3}
	\Alg(\theta,S) = \theta - \alpha \nabla_\theta \Loss (\theta, Q) \Rightarrow \frac{d}{d\theta}\Alg(\theta, S) = I - \alpha \nabla^2_\theta \Loss (\theta, S)
\end{equation}
 
 که در رابطه فوق، محاسبه مشتق‌های مرتبه دوم (Hessian) می‌تواند بسیار سخت یا پرهزینه باشد چرا که لازم است تا کل گراف محاسباتی در طول مسیر محاسبه
 $\Alg(\theta, S)$
  نگه داشته شود تا بتوان گرادیان را از روی آن عبور داده و به مراحل قبلی رساند.
  
در این سوال قصد داریم تا تکنیکی معرفی کنیم که با استفاده از آن این مشکلات مرتفع شوند. برای این منظور، فرض کنید 
$\Alg(\theta, S)$
به صورت زیر پیشنهاد شده است:

\begin{equation}		\label{eq:4}
	\phi = \Alg(\theta,S) = \argmin_{\phi'} \Loss(\phi', S) + \frac{\lambda}{2}||\phi' - \theta||^2
\end{equation}
 
که $\lambda$ یک هایپرپارامتر است و هر چه مقدار آن بیشتر باشد، باعث می‌شود تا جواب بهینه‌سازی درونی، به نقطه شروع خود یعنی
$\theta$
نزدیک‌تر بماند. بهینه‌سازی \ref{eq:4}
را می‌توان با انجام چندین گام بهینه‌سازی تکرار شونده (Iterative) حل کرد اما مشکل آن جاست که امکان عبور گرادیان از چنین محاسباتی وجود ندارد. با در نظر گرفتن این مسئله، به پرسش‌های زیر پاسخ دهید:

\begin{enumerate}
\item
فرض کنید ما قادر هستیم تا بهینه‌سازی 
\ref{eq:4}
را به صورت کامل حل کنیم و 
$\phi$
را به عنوان جواب بهینه دقیق آن به دست آورده‌ایم. از این مسئله استفاده کنید و 
$\frac{d\phi}{d\theta}$
را محاسبه کنید (راهنمایی: در نقطه بهینه دقیق، مشتق 
$ \Loss(\phi', S) + \frac{\lambda}{2}||\phi' - \theta||^2$
نسبت به 
$\phi'$
صفر خواهد بود
).

\item
اگر مراحل پرسش قبل را به درستی طی کرده باشید، در جواب خود به یک عبارت حاوی مشتق مرتبه دوم $\nabla^2 \Loss$ (یا همان ماتریس 
\lr{Hessian}
)
می‌رسید. محاسبه این عبارت چه تفاوتی با مشتق مرتبه دوم موجود در رابطه 
\ref{eq:3}
دارد؟ استفاده از این تابع
$\Alg$
پیشنهادی چه مزیتی نسبت به MAML دارد؟

\item
به عنوان جمع‌بندی، الگوریتمی که متا-یادگیر در هر اپیزود طی می‌کند را به صورت گام گام شرح دهید.

\end{enumerate}

\textbf{پاسخ}

\begin{enumerate}
\item

\begin{subequations}
	\begin{alignat}{2}
		\frac{d}{d\phi'} \Loss(\phi', S) + \frac{\lambda}{2}||\phi' - \theta||^2 = \nabla_{\phi'} \Loss(\phi', S) |_{\phi' = \phi} - \lambda (\phi'-\theta) |_{\phi' = \phi} = 0 \\ 
		\Rightarrow \phi = \theta - \frac{1}{\lambda} \nabla_\phi \Loss (\phi, S) \\
		\Rightarrow \frac{d}{d\theta} \phi = I - \frac{1}{\lambda} \nabla^2_\phi \Loss (\phi, S) \times \frac{d\phi}{d\theta} \\ 
		\Rightarrow \frac{d\phi}{d\theta} = 
		(I +‌ 
		\frac{1}{\lambda} \nabla^2_\phi \Loss (\phi, S)
		)^{-1} \label{eq:51}
	\end{alignat}
\end{subequations}

\item
مشتق مرتبه دوم به دست آمده در الگوریتم MAML به صورت 
$\nabla^2_\theta \Loss(\theta, S)$
می‌باشد این در حالیست که در روش معرفی شده با محاسبه
$\nabla^2_\phi \Loss(\phi, S)$
مواجه می‌شویم. این بدان معناست که مشتق دوم مورد نظر، کافیست در نقطه بهینه حاصل از حل دقیق بهینه‌سازی
\ref{eq:4}
نوشته شود و به مسیری که در گام‌های محاسبه \ref{eq:4}
طی شده است، هیچ وابستگی وجود ندارد. 
توجه کنید که 
$\theta$
همان نقطه شروع بهینه‌سازی است در حالی که 
$\phi$
نقطه نهایی بهینه‌سازی محسوب می‌شود.
لذا در حل 
\ref{eq:4}
کافیست تا گرادیان 
$\theta$
و
$\phi$
را قطع کنیم، بهینه‌سازی 
\ref{eq:4}
را حل کرده و گرادیان مورد نیاز برای آپدیت 
$\theta$
را با کمک روابط 
\ref{eq:2}
و
\ref{eq:51}
به دست آوریم. این درحالیست که در رویکرد MAML (مخصوصاً‌ زمانی که بیش از یک گام بهینه‌سازی در حلقه داخلی بر می‌داریم)، لازم است تا کل گراف محاسباتی و کل وزن‌های محاسبه شده در میان مسیر را نگه داری کنیم تا بتوانیم مشتق‌های مرتبه دو را محاسبه کنیم. 

\item
\begin{itemize}
\item
یک وظیفه (Task) به صورت 
$\mathcal{T} \in D_{meta-train}$
نمونه برداری می‌کنیم که شامل داده‌های پشتیبان (Support)
$S$
و پرسمان (Query)
$Q$
می‌باشد.
\item
با در دست داشتن داده‌های $S$، بهینه‌سازی \ref{eq:4} 
را با روش‌های مرسوم بهینه‌سازی انجام می‌دهیم و حاصل را $\phi$ می‌نامیم.
\item
طبق رابطه 
\ref{eq:51}
مشتق 
$\phi$
نسبت به 
$\theta$
را محاسبه می‌کنیم.
\item
با کمک داده‌های 
$Q$،
عبارت 
$\nabla_{\phi} \Loss (\phi, Q) |_{\phi = \Alg(\theta, S)} $
را محاسبه می‌کنیم.
\item
از ضرب دو رابطه محاسبه شده در دو مورد اخیر، 
$\nabla_{\theta} \Loss (\Alg(\theta, S), Q)$
را محاسبه کرده و با کمک این گرادیان متا-پارامتر‌های 
$\theta$
را آپدیت می‌کنیم.
\end{itemize}

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% problem 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\problem{روش‌های مبتنی بر یادگیری متریک}
روش‌های یادگیری متریک یکی دیگر از روش‌هایی هستند که در درس به عنوان یکی از اعضای خانواده متا-یادگیری با آن‌ها آشنا شدید. در این روش‌ها هدف آن است که یک شبکه استخراج ویژگی مثل
$f_\theta(x)$
یاد گرفته شود تا داده‌های کلاس یکسان را در فضای نمایش مخفی در کنار یکدیگر تصویر کند. پارامترهای 
$\theta$
متا-پارامترهای مدل در نظر گرفته می‌شوند در طول متا-یادگیری آموزش داده می‌شوند. از آنجایی که 
$f_\theta(x)$
صرفاً یک فضای نمایشی (
\lr{Representation Space}
) فراهم می‌کند، برای کامل کردن شبکه نیاز به یک دسته‌بند (یادگیر پایه) پارامتریک یا نان-پارامتریک داریم که روی این فضای نمایشی قرار گرفته، از داده‌های پشتیبان برای آماده‌سازی خود استفاده کرده و با کمک آن‌ها عمل دسته‌بندی نمونه‌های پرسمان را انجام دهد. پارامترهای دسته‌بند معرفی شده را به عنوان پارامترهای سریع می‌شناسند و آن‌ها را با 
$\phi$
نمایش می‌دهند. این پارامترها مختص هر وظیفه به دست آمده و برای وظیفه بعدی تغییر می‌کنند.

در این روش‌ها یکی از تصمیمات مهم در زمینه طراحی الگوریتم انتخاب مناسب همین دسته‌بند می‌باشد. از جمله انتخاب‌های موجود برای این خانواده، انتخاب روش  
\lr{Nearest Neighbour}
می‌باشد. همچنین روش دیگری که در مقاله ProtoNet معرفی شد استفاده از دسته‌بندهای مبتنی بر پروتوتایپ دسته‌ها (با میانگین گیری از داده‌های موجود در مجموعه پشتیبان از هر کلاس) می‌باشد. 
مشکلی که متایادگیری مبتنی بر پروتوتایپ دارند این است که دسته‌بند ساده‌ای دارند و تعمیم‌پذیری دسته‌بند در فاز متا-ارزیابی کم می‌باشد. به همین دلیل در مقاله
\lr{\href{https://arxiv.org/pdf/1805.08136}{Bertinetto 2018}}
به بررسی دو دسته‌بند رایج در یادگیری ماشین (\lr{Logistic Regression, Ridge Regression}) و نحوه استفاده موثر آن در مسئله متایادگیری پرداخته است. با مطالعه مقاله و راهنمایی های داده‌ شده در زیر،‌ به سوالات پاسخ دهید

\begin{enumerate}
	\item
	توضیح دهید که در نگاه اول، استفاده از این دسته‌بندها چه مشکلی می‌تواند برای فرایند متا-آموزش ایجاد کند؟ چرا استفاده از رویکردهای پروتوتایپی یا KNN این مشکل را ایجاد نمی‌کند؟ (راهنمایی: پاسخ این مورد غیر مرتبط با پرسش قبل نیست)

	\item
	توضیح دهید که در مقاله معرفی شده، چگونه مشکل معرفی شده را حل می‌کند؟ تفاوت رویکردی که برای
	 \lr{Ridge Regression}
	  و 
	  \lr{Logistic Regression}
	  به کار گرفته می‌شود را توضیح دهید.
	
	\item
	دو ماتریس
	$X \in {\mathbb{R}^{n \times d}}$
	و
	$Y \in {\mathbb{R}^{n \times l}}$
	را در نظر بگیرید که n تعداد داده‌ها و d اندازه بردار باز‌نمایی هر داده و l تعداد برچسب‌های موجود در دسته می‌باشد. ثابت کنید که دو رابطه زیر در صورتی که
	$\lambda  > 0$
	باشد، با هم برابر می‌باشند و نحوه استفاده آن در دسته‌بند 
	\lr{Ridge Regression}
	 را توضیح دهید:
	$$
	{\left( {{X^T}X + \lambda I} \right)^{ - 1}}{X^T}Y = {X^T}{\left( {X{X^T} + \lambda I} \right)^{ - 1}}Y
	$$
	
	\item
	توضیح دهید که برای انجام متایادگیری استفاده از کدام یک از دو رابطه بالا بهتر می‌باشد و چرا؟
	
	\item
	در مقاله معرفی شده، برای محاسبه وزن‌های دسته‌بند
	\lr{Logistic Regression}
	از بهینه‌سازی با روش 
	\lr{Newton}
استفاده شده است. دلیل این امر را بیان کنید و همچنین در مورد خود
	\lr{Newton's Method}
	تحقیق کنید و رابطه به روزرسانی و نحوه بدست آوردن این رابطه را بنویسید.
	
	\item
	تعاریف زیر را در نظر بگیرید:
	
	$$
	\begin{array}{l}
		{A_t} = diag({q_t})\\
		q_t^{\left( i \right)} = \sigma \left( {\omega _t^T{x^{\left( i \right)}}} \right)\left( {1 - \sigma \left( {\omega _t^T{x^{\left( i \right)}}} \right)} \right)\\
		B_t^{\left( i \right)} = \sigma \left( {\omega _t^T{x^{\left( i \right)}}} \right) - {y^{\left( i \right)}}
	\end{array}
	$$
	که
	$A \in {\mathbb{R}^{n \times n}}$
	یک ماتریس قطری
	و
	$B \in {\mathbb{R}^n}$
	می‌باشد. 
	
	با اعمال
	\lr{Newton's Method}
	روی تابع هزینه این دسته‌بند، به رابطه به‌روزرسانی زیر که مشابه رابطه 7 مقاله می‌باشد برسید. (رابطه 7 مقاله خود دارای اشکالات Notation ای بود)

	$$
	{\omega _{t + 1}} = {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {{X^T}{A_t}X{\omega _t} - {X^T}{B_t}} \right)
	$$

\end{enumerate}


\textbf{پاسخ:}

\begin{enumerate}
	\item
دو دسته بند ذکر شده، دسته‌بندهایی پارامتریک هستند و برای آن که پارامترهای آن‌ها محاسبه شود، نیاز است تا یک دستگاه بهینه‌سازی حل شود. یکی از روش‌های حل دستگاه، استفاده از رویکردهای iterative و استفاده مستقیم از رویکرد 
\lr{Gradient Decent}
 است. بدی استفاده از این نوع Solver آن است که مراحل انجام شده در رویکرد iterative قابلیت عبور گرادیان را ندارند و این باعث به مشکل خوردن متا-یادگیری می‌شود. به عبارت دقیق‌تر، فرض کنید که نمونه‌های پشتیبان را از شبکه استخراج ویژگی عبور داده‌اید و آن‌ها را در فضای نمایشی تعبیه کرده‌اید. سپس با یک رویکرد iterative بهینه‌سازی مربوط به 
 \lr{Ridge Regression}
  را انجام داده و وزن‌های دسته‌بند را به دست می‌آورید. مشکلی که وجود دارد آن است که نمی‌توان گرادیان Meta-Loss را از وزن‌های به دست آمده عبور داد و از طریق آن شبکه استخراج ویژگی و پارامترهای 
$\theta$
را آپدیت کرد. این در حالیست که با استفاده از KNN، به راحتی می‌توان وزن‌های 
$\theta$
را آپدیت کرد چرا که دسته‌بند مستقیماً با خود نمونه‌های هر کلاس کار می‌کند. با استفاده از این رویکرد می‌توان گرادیان را از نمونه‌های موجود هر کلاس عبور داد و از این طریق چینش نمونه‌های یک کلاس را طوری تنظیم کرد که نمونه‌های یک کلاس در فضای نمایش نزدیک یک دیگر بیفتند. رویکرد مشابهی در مورد دسته‌بند پروتوتایپی وجود دارد چرا که عملیات میانگین‌گیری روی نمونه‌های یک کلاس مشکلی برای عبور مسیر گرادیان ایجاد نمی‌کند و با آپدیت کردن 
$\theta$
می‌توان نمونه‌ها را طوری در فضا تعبیه کرد که نمونه‌های مربوط به یک کلاس خاص در نزدیکی پروتوتایپ کلاس خودشان قرار بگیرند.
	\item
	این مقاله برای حل مشکل
	 \lr{Ridge Regression}
	، به جای حل iterative آن، یک جواب Closed-form به عنوان وزن‌های بهینه معرفی می‌کند. این جواب بسته به راحتی قابلیت عبور گرادیان به لایه‌های عقبی را فراهم می‌کند.
	
	از سویی برای دسته‌بند
	 \lr{Logistic Regression}
	 ، از رویکرد iterative خاصی استفاده می‌کند و همزمان نشان می‌دهد که این رویکرد قابلیت عبور گرادیان از تک تک مراحل iterative را فراهم می‌کند. رویکرد مورد استفاده 
	\lr{Newton's Method}
	نام دارد.
	
	\item
	باتوجه به اینکه ماتریس $Y$ در هردو طرف مساوی از سمت راست در معادله ضرب شده است،‌ پس تنها کافی است که اثبات کنیم:
	$$
	{\left( {{X^T}X + \lambda I} \right)^{ - 1}}{X^T} = {X^T}{\left( {X{X^T} + \lambda I} \right)^{ - 1}}
	$$
	برای شروع اثبات در رابطه زیر را در نظر بگیرید:
	$$
	\lambda {X^T} = \lambda {X^T}
	$$
	
	ماتریس همانی را برای یک سمت از رابطه مساوی بالا از سمت چپ ماتریس 
	${X^T}$
	و یک بار از سمت راست ماتریس،‌ ضرب می‌کنیم:
	$$
	\lambda {I_d}{X^T} = \lambda {X^T}{I_n}
	$$
	حال عبارت
	${X^T}X{X^T}$
	را به دو سمت مساوی اضافه می‌کنیم.
	$$
	{X^T}X{X^T} + \lambda {I_d}{X^T} = {X^T}X{X^T} + \lambda {X^T}{I_n}
	$$
	با فاکتورگیری داریم:
	$$
	\left( {{X^T}X + \lambda {I_d}} \right){X^T} = {X^T}\left( {X{X^T} + \lambda {I_n}} \right)
	$$
	حال اگر در دو طرف تساوی، عبارت
	${\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}$
	را از چپ و عبارت
	${\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}}$
	را از سمت راست ضرب کنیم داریم:
	$$
	{\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}\left( {{X^T}X + \lambda {I_d}} \right){X^T}{\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}} = {\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}{X^T}\left( {X{X^T} + \lambda {I_n}} \right){\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}}
	$$
	با ساده‌سازی داریم:
	$$
	{X^T}{\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}} = {\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}{X^T}
	$$
	
	که مطلوب سوال می‌باشد. 
	
		این نکته لازم به ذکر می‌باشد که ماتریس‌هایی که معکوس آن را در اثبات بالا استفاده کردیم هردو ماتریس‌های مثبت نیمه‌معین می‌باشند و بنابراین حتما معکوس‌پذیر می‌باشند.
	
	رابطه معرفی شده، همان جواب Closed-Form برای دسته‌بند 
	\lr{Ridge Regression}
	است و همانطور که مشاهده می‌شود، در محاسبه این وزن‌ها تنها از ضرب ماتریسی و معکوس گیری استفاده شده است که این‌ اپراتورها قابلیت عبور گرادیان از خود را فراهم می‌کنند.
	
\item
	
	برای انجام متایادگیری استفاده از رابطه
	${X^T}{\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}}$
	بهینه‌تر می‌باشد. چون در این رابطه نیاز به محاسبه معکوس یک ماتریس با ابعاد
	$n \times n$
	داریم ولی در حالت دیگر نیاز به محاسبه معکوس ماتریسی به ابعاد
	$d \times d$
	می‌باشد که مقدار $d$ که بیانگر ابعاد بازنمایی در شبکه عصبی می‌باشد که به مراتب خیلی بزرگتر از تعداد نمونه‌ها در مسئله‌های متایادگیری می‌باشد چرا که که تعداد نمونه‌های پشتیبان در مسائل few-shot خیلی کم می‌باشد.
	
	\item
	به دلیل محدودیت تعداد به‌روزرسانی پارامترها در حلقه درونی الگوریتم،‌از
	\lr{Newton's Method}
	برای همگرایی سریع‌تر به نسبت گرادیان گیری ساده استفاده شده است.
	در
	\lr{Newton's Method}
	علاوه بر گرادیان،‌ اطلاعات مشتق دوم نیز استفاده می‌شود. توجه کنید که در تابع هزینه‌های محدب (از جمله همین 
	\lr{Logistic Regression}
	)
	استفاده از این رویکرد می‌تواند خیلی سریع ما را به نقطه بهینه همگرا کند.
	در این روش با نوشتن بسط Taylor حول یک نقطه داریم:
	$$
	f\left( {x + t} \right) = f\left( x \right) + f'\left( x \right)t + \frac{{f''\left( x \right){t^2}}}{2}
	$$
	
	در رابطه بالا برای کمینه کردن مقدار تابع، نسبت به پارامتر $t$ که جهت به‌روزرسانی و حرکت می‌باشد مشتق میگیریم که جهت بهینه به‌روزرسانی را پیدا کنیم:
	$$
	\frac{{dy}}{{dx}}\left( {f\left( x \right) + f'\left( x \right)t + \frac{{f''\left( x \right){t^2}}}{2}} \right) = f'\left( x \right) + f''\left( x \right)t = 0
	$$
	$$
	{t^*} =  - \frac{{f'\left( x \right)}}{{f''\left( x \right)}}
	$$
	
	\item
	
	هدف سوال کمینه‌کردن منفی لگاریتم بیشینه درست‌نمایی به همراه یک جمله منظم‌سازی می‌باشد.
	$$
	P\left( {Y|\omega ,X} \right) = \prod\limits_{i = 1}^N {{{\left( {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right)}^{{y^{\left( i \right)}}}}{{\left( {1 - \sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right)}^{1 - {y^{\left( i \right)}}}}}
	$$
	$$
	L =  - \log P\left( {Y|\omega ,X} \right) + \lambda {\left\| \omega  \right\|^2} =  - \sum\limits_{i = 1}^N {\left[ {{y^{\left( i \right)}}\log \left( {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right) + \left( {1 - {y^{\left( i \right)}}} \right)\log \left( {1 - \sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right)} \right]}  + \lambda {\left\| \omega  \right\|^2}
	$$
	
	حال با گرادیان گیری مقادیر گرادیان اول و دوم را حساب می‌کنیم:
	
	$$
	{\nabla _\omega }L = \sum\limits_{i = 1}^N {\left( {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right) - {y^{\left( i \right)}}} \right){x^{{{\left( i \right)}^T}}}}
	$$
	$$
	\nabla _\omega ^2L = \sum\limits_{i = 1}^N {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)\left( {1 - \sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right){x^{{{\left( i \right)}^T}}}{x^{\left( i \right)}}}
	$$
	
	
	حال اگر سیگماهای بالا را به ضرب ماتریسی تبدیل کنیم،‌ طبق رابطه به‌روزرسانی داریم:
	
	$$
	\begin{aligned}
		{\omega _{t + 1}} & = {\omega _t} - {H^{ - 1}}\nabla L\\
		& = {\omega _t} - {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {{X^T}{B_t} + \lambda {\omega _t}} \right)\\
		&‌= {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {\left( {{X^T}{A_t}X + \lambda I} \right){\omega _t} - {X^T}{B_t} - \lambda {\omega _t}} \right)\\
		&‌= {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {{X^T}{A_t}X{\omega _t} - {X^T}{B_t}} \right)
	\end{aligned}
	$$
	
	$$
	{\omega _{t + 1}} = {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {{X^T}{A_t}X{\omega _t} - {X^T}{B_t}} \right)
	$$
	
\end{enumerate}


\problem{(نظری) تنظیم توزیع برای یادگیری چند‌‌نمونه‌ای (۴۰ نمره)}
یکی از ریسک‌های احتمالی در یادگیری چندنمونه‌ای احتمال بیش برازش بر روی دادگان کم‌تعداد آموزشی است. در این
\href{https://arxiv.org/abs/2101.06395}{مقاله}
روشی پیشنهاد شده است تا به کمک استخراج مشخصات آماری کلاس‌های حاضر در متاآموزش بتوان توزیع دادگان کلاس‌های حاضر در متاتست را تنظیم کرد. این مقاله را به دقت خوانده و به سوالات زیر به طور کامل پاسخ دهید:

\begin{enumerate}

\item
از آنجایی که ممکن است توزیع دادگان هر کلاس حاضر در متاآموزش گاوسی نباشد و دارای مقداری کشیدگی باشد؛ در نظر گرفتن این توزیع‌ها به عنوان توزیع گاوسی و استخراج میانگین و کواریانس از آن‌ها میتواند اشتباه باشد. توضیح دهید این مقاله چه روشی را برای حل مشکل کشیدگی توزیع دادگان متاآموزش اتخاد کرده است و چگونه این روش موجب حل مشکل کشیدگی توزیع می‌شود؟

\item
پس از استخراج میانگین و کواریانس کلاس‌های حاضر در متاآموزش، مدل ارائه شده اقدام به تنظیم توزیع دادگان حاضر در متاتست می‌کند. به صورت کامل و با نوشتن روابط ریاضی مربوطه بیان کنید این تنظیم توزیع به چه صورت انجام می‌پذیرد و وجود کلاس‌های مشابه در متاترین به کلاس منظور در متاتست چه کمکی به تنظیم توزیع می‌کند؟

\item
در تنظیماتی که در هنگام متاتست از هر کلاس بیش از یک نمونه آموزش داشته باشیم این مدل به جای میانگین‌گیری از نمونه‌ها، برای هر کدام از 
\lr{k}
نمونه آموزش اقدام به تنظیم توزیع جداگانه می‌کند. توضیح دهید توزیع تنظیم جداگانه چه مزیتی نسبت به میانگین گیری نمونه‌ها و سپس یک توزیع تنظیم دارد؟

\end{enumerate}




\problem{(عملی) یادگیری چندنمونه‌ای از طریق یادگیری متریک (۴۰ نمره)}
در این سوال قصد داریم تا مدل یادگیرنده
شبکه
\href{https://arxiv.org/abs/1703.05175}{\lr{Prototypical}}
را مورد پیاده‌سازی و بررسی قرار دهیم. به این منظور هر دو زیر مجموعه‌های آموزش و تست دادگان
\lr{CIFAR100}
را دریافت کرده و سپس آن‌ها را به یکدیگر الحاق نمایید. 
سپس این دادگان را به سه زیر مجموعه
متاآموزش، متااعتبارسنجی و متاتست تقسیم کنید. به این صورت که دادگان آموزش شامل دادگان ۷۰ کلاس، دادگان اعتبارسنجی شامل ۲۰ کلاس و دادگان  کلاس تست شامل ۱۰ دیگر باشند.
در گام بعدی بایستی یک 
\lr{Sampler}
پیاده‌سازی کنید که با گرفتن پارامترهای
\lr{Way}
و
\lr{Shot}
بتواند دادگان
اتکا و پرسمان برای یک وظیفه را تولید کنند ( در واقع این ماژول با هر فراخوانی دو مجموعه داده به اندازه
$Way * Shot$
برای اتکا و پرسمان خروجی میدهد). این ماژول در واقع هر بار یک اپیزود را تولید میکند.
در طی آزمایش‌های زیر از ماژول
\lr{ProtoNetBack}
که در فایل‌های پیوستی قرار داده شده است به عنوان شبکه  تکیه استخراج ویژگی استفاده کنید و در جلوی آن دو لایه تمام متصل با اندازه دلخواه قرار دهید.

\begin{enumerate}


\item
دسته‌بند را با تنظیمات
\lr{8-shot, 10-way }
آموزش دهید و سپس دقت مدل را بر روی دادگان متاتست گزارش دهید.
انتظار می‌رود دقت در این بخش بیشتر از ۵۰ درصد باشد.

\item
به ازای هر یک از تنظیمات
$shot \in \{1, 2, 4, 8, 16\}$
و
\lr{10-way}
آزمایش بالا را تکرار کرده و نمودار دقت متاتست بر حسب
\lr{shot}
را رسم نمایید.

\item
حال به ازای هر یک از تنظیمات
$way \in \{2, 4, 8, 16, 32\}$
و
\lr{5-shot}
آزمایش را تکرار کرده و نمودار دقت متاتست بر حسب
\lr{way}
را رسم نمایید.
(دقت کنید که در هنگام متاتست از تنظیمات
\lr{5-shot, 10-way}
استفاده نمایید)


\item
حال در هنگام متاآموزش با تنظیمات
\lr{10-shot, 10-way}
دسته‌بند را آموزش دهید.
در هنگام متاتست اما متاتست را به ازای هر یک از تنظیمات
$shot \in \{1, 5,10, 15, 20\} $
انجام دهید و نمودار دقت آن را بر حسب 
\lr{shot}
رسم نمایید.

\end{enumerate}




\problem{(عملی) متایادگیری براساس بهینه‌سازی (۴۰ نمره)}
در این سوال قصد داریم تا مدل معروف دسته متایادگیری براساس بهینه‌سازی،‌MAML،‌ را پیاده‌سازی نماییم. مقاله مرتبط با این کار،
\href{https://arxiv.org/pdf/1703.03400}{این مقاله}
می‌باشد. در Notebook داده شده تمام پارامترهای مسئله و مراحل حل به صورت گام به گام تشریح شده است.
سوال از دو بخش اصلی تشکیل شده است که در بخش اول به دلیل کاهش هزینه آموزش بخش عمده شبکه به صورت pretrained شده در اختیار شما قرار داده شده است و شما تنها روی بخش مشخص شده شبکه فرایند متایادگیری را انجام خواهید داد. در بخش اول قرار است تاثیر تعداد گام‌های به‌روزرسانی مدل در حلقه داخلی الگوریتم، مورد بررسی قرار گیرد. از شما خواسته شده است که به ازای مقادیر 1 تا 3 این مورد را انجام دهید و نتیجه هر حالت را مقایسه و گزارش کنید. در بخش دوم نیز از شما خواسته شده است که حال با یک گام به‌روزرسانی حلقه داخلی‌، کل ساختار مدل (مدل متایادگیری بخش اول + ساختار مدل pretrained داده شده) را به صورت متاپارامتر در نظر بگیرید و متایادگیری را روی آن انجام دهید. در نهایت نتایج بدست آمده از هردو بخش را تحلیل و گزارش نمایید.







\end{document}
