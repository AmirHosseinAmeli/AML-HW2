\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\newcommand{\eqn}{\[
    \stcomp{(A \cup B)} = \stcomp{A} \cap \stcomp{B}
\]}
\usepackage{bbm}
\usepackage{amsfonts}
\usepackage{graphicx}%بسته‌ای برای اضافه کردن عکس
\usepackage{float}
\usepackage[colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{geometry}
\usepackage {tikz}
\usepackage{color}
\usepackage{amssymb}
\usepackage{enumitem}
\setlist[enumerate,1]{label=(\alph*) , itemsep=8pt,topsep=8pt}
\setlist[enumerate,2]{label=\arabic*. ,itemsep=10pt,topsep=10pt}
\setlist[enumerate,3]{label=\alph*. ,itemsep=10pt,topsep=10pt}
\usepackage{xepersian}
\settextfont[ExternalLocation=Niloofar/,
ItalicFont = XB-NiloofarIt.ttf,
BoldFont = XB-NiloofarBd.ttf,
BoldItalicFont = XB-NiloofarBdIt.ttf
]{XB-Niloofar.ttf}


%\underset{x}{\operatorname{argmax}} 
\DeclareMathOperator*{\argmin}{arg\,min}	
 
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=15mm,
 }
%دستور زیر برای تعیین فونت متن فارسی می‌باشد.

%\settextfont[Scale=1]{XB Niloofar}%{Yas}
%\setlength{\parindent}{0pt}

\newcounter{probcnt}

\NewDocumentCommand{\problem}{m}{
\stepcounter{probcnt}\bigskip\medskip{\underline{\textbf{
 	 سوال
   \arabic{probcnt}:
   #1
}}}
\nopagebreak\par\medskip
\vspace{1mm}
}

\newcommand{\heading}[4]{
\parindent=0em

\rightline{
\makebox[6em][c]{
\includegraphics[height=1.6cm]{images/logo}
}}
\vspace{-.5em}
{\scriptsize\bf دانشکده‌ی مهندسی کامپیوتر}
\hfill {\small
مدرس: دکتر مهدیه سلیمانی \ 
}\\[-5.3em]
\leftline{\hfill\Large\bf 
مفاهیم پیشرفته در یادگیری ماشین
}\\[.8em]
\leftline{\hfill\bf 
نیم‌سال دوم 401-1400
}\\[1.5em]
\hrule height .12em
\normalsize
\vspace{0.2em} 
\makebox[5cm][r]{#1}
\hfill 
\makebox[5cm][c]{\large #2} 
\hfill
\makebox[5cm][l]{\small #3 #4}
\vspace{1mm} 
\hrule height .1em
}

\newcommand{\hwhead}[3]{\heading{#1}{#2}{زمان تحویل:}{#3}}
\DeclareMathOperator{\Wp}{\hat{W}^{(0)}}
\DeclareMathOperator{\Wh}{\hat{W}}
\DeclareMathOperator{\Lossh}{\hat{\mathcal{L}}}
\DeclareMathOperator{\Loss}{\mathcal{L}}
\DeclareMathOperator{\Alg}{\mathcal{A}lg}
\DeclareMathOperator{\T}{\mathcal{T}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\grad}{\nabla}

\begin{document}
 
\vspace{2mm}

\centerline{ به نام خدا}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ویرایش ددلاین و شماره و عنوان تمرین %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\hwhead{تمرین سری دوم}{روش های متا-یادگیری مبتنی بر بهینه سازی و یادگیری متریک}{19 فروردین}

 \vspace{0.5cm}
لطفا نکات زیر را رعایت کنید:
\begin{itemize}
\item[-]
سوالات خود را از طریق پست مربوط به تمرین در \lr{Quera} مطرح کنید.
\item[-]
در هر کدام از سوالات، اگر از منابع خاصی استفاده کرده‌اید باید آن را ذکر کنید.
\item[-] 
 پاسخ ارسالی واضح و خوانا باشد.

\item[-]
تمام پاسخ‌های خود را در یک فایل با فرمت \lr{HW\#\_[SID]\_[Fullname].zip} روی کوئرا قرار دهید.
\item[-]
برای ارسال هر تمرین تا ساعت ۲۳:۵۹ روز ددلاین فرصت دارید. علاوه بر آن، در هر تمرین می توانید تا سقف هفت روز از تأخیر مجاز باقیمانده‌ی خود استفاده کنید.

\item[-]
برای کسب نمره کامل در این تمرین کافیست تا 160 نمره از 200 نمره را کسب نمایید (40 نمره امتیازی).

\end{itemize}

\hrule height .1em

\problem{
(نظری) متا-یادگیری مبتنی بر بهینه‌سازی دو سطحی (25 نمره)
}
همانطور که در جلسات درس مشاهده کرده‌اید، یکی از روش‌های متا-یادگیری
\LTRfootnote{Meta-Learning}
، خانواده بهینه‌سازی دو سطحی
\LTRfootnote{Bi-Level Optimization}
 بوده که مهمترین کار در این زمینه روش  
 \href{https://arxiv.org/abs/1703.03400}{MAML}
 \LTRfootnote{Model Agnostic Meta-Learning}
 می‌باشد. در این خانواده از روش‌ها، متا-پارامترها
\LTRfootnote{Meta-Parameters}
 (پارامترهای آهسته) همبعد با پارامترهای مختص وظیفه 
 \LTRfootnote{Task-Specific  Parameters}
 (پارامترهای سریع) بوده و به عنوان یک نقطه شروع برای کل وزن‌های شبکه عمل می‌کنند. به طور دقیق‌تر، اگر توزیع وظایف 
\LTRfootnote{Tasks}
 را به صورت 
$p(\T)$
در نظر بگیریم، می‌توان رابطه زیر را برای یادگیری متا-پارامترها ارائه داد:

\begin{subequations}
	\begin{alignat}{2}
		\theta^* = \argmin_{\theta} \E_{\T = (S, Q) \sim p(\T)} [\Loss (\phi, Q)]\\
		Where \quad \phi = \Alg(\theta, S)
		 \label{eq:0}
	\end{alignat}
\end{subequations}

که در این رابطه 
$S$
مجموعه داده‌های پشتیبان 
\LTRfootnote{Support}
 و 
$Q$
مجموعه داده‌های پرسمان
 \LTRfootnote {Query}
  مربوط به هر وظیفه 
  \LTRfootnote{Task}
   را نشان می‌دهد. در این رابطه، محاسبه پارامترهای سریع $\phi$ توسط روش 
$\Alg$
انجام می‌شود که در مقالات مربوطه به طرق مختلفی انتخاب شده و بهینه‌سازی داخلی 
\LTRfootnote{Inner-Level Optimization}
نامیده می‌شود. همچنین در رابطه فوق، بهینه‌سازی خارجی 
\LTRfootnote{Outer-Level Optimization}
که روی پارامترهای $\theta$ صورت می‌پذیرد، به شکل 
$\argmin$
نمایش داده شده است. 

برای انجام بهینه‌سازی خارجی، لازم است تا از تابع معرفی شده نسبت به 
$\theta$
گرادیان را به صورت زیر محاسبه کرده و $\theta$ را از طریق آن به‌روزرسانی نماییم:

\begin{equation} \label{eq:1}
		\nabla_{\theta} \E [\Loss (\phi, Q)] = 
		\E [\nabla_{\theta} \Loss (\Alg(\theta, S), Q)]
\end{equation}

برای محاسبه عبارت فوق، از قاعده زنجیره‌ای مشتق استفاده می‌کنیم:

\begin{equation}		\label{eq:2}
		\nabla_{\theta} \Loss (\Alg(\theta, S), Q) 		= \nabla_{\phi} \Loss (\phi, Q) |_{\phi = \Alg(\theta, S)} 
		\times \frac{d}{d\theta}\Alg(\theta, S)
\end{equation}

همانطور که مشاهده می‌کنید، رابطه فوق از دو جمله تشکیل شده است؛ محاسبه جمله اول نسبتاً راحت است. چرا که کافیست تا از 
$\Loss$
مشتق گرفته و مقدار 
$\Alg(\theta, S)$
را در آن جایگذاری کنیم و در این صورت گرادیانی از 
$\Alg(\theta, S)$
عبور نمی‌کند. این در حالیست که برای محاسبه جمله دوم، لازم است تا عملیات مشتق‌گیری را از داخل الگوریتم $\Alg(\theta, S)$ عبور دهیم. این مسئله می‌تواند مشکل‌زا باشد چرا که ممکن است $\Alg(\theta, S)$ اصلاً قابلیت عبور گرادیان را نداشته باشد یا اگر دارد ممکن است منجر به محاسبات پرهزینه شود. به عنوان مثال، در روش MAML داریم:

\begin{equation}		\label{eq:3}
	\Alg(\theta,S) = \theta - \alpha \nabla_\theta \Loss (\theta, Q) \Rightarrow \frac{d}{d\theta}\Alg(\theta, S) = I - \alpha \nabla^2_\theta \Loss (\theta, S)
\end{equation}
 
 که در رابطه فوق، محاسبه مشتق‌های مرتبه دوم (Hessian) می‌تواند بسیار سخت یا پرهزینه باشد چرا که لازم است تا کل گراف محاسباتی در طول مسیر محاسبه
 $\Alg(\theta, S)$
  نگه داشته شود تا بتوان گرادیان را از روی آن عبور داده و به مراحل قبلی رساند.
    
در این سوال قصد داریم تا تکنیکی معرفی کنیم که این مشکلات مرتفع شوند. برای این منظور، فرض کنید 
$\Alg(\theta, S)$
به صورت زیر پیشنهاد شده است:

\begin{equation}		\label{eq:4}
	\phi = \Alg(\theta,S) = \argmin_{\phi'} \Loss(\phi', S) + \frac{\lambda}{2}||\phi' - \theta||^2
\end{equation}
 
که $\lambda$ یک هایپرپارامتر است و هر چه مقدار آن بیشتر باشد، باعث می‌شود تا جواب بهینه‌سازی درونی، به نقطه شروع خود یعنی
$\theta$
نزدیک‌تر بماند. بهینه‌سازی \ref{eq:4}
را می‌توان با انجام چندین گام بهینه‌سازی تکرار شونده
 \LTRfootnote{Iterative}
  حل کرد اما مشکل آن جاست که امکان عبور گرادیان از چنین محاسباتی وجود ندارد. با در نظر گرفتن این مسئله، به پرسش‌های زیر پاسخ دهید:

\begin{enumerate}
\item
فرض کنید ما قادر هستیم تا بهینه‌سازی 
\ref{eq:4}
را به صورت کامل حل کنیم و 
$\phi$
را به عنوان جواب بهینه دقیق آن به دست آورده‌ایم. از این مسئله استفاده کنید و 
$\frac{d\phi}{d\theta}$
را محاسبه کنید (راهنمایی: در نقطه بهینه دقیق، مشتق 
$ \Loss(\phi', S) + \frac{\lambda}{2}||\phi' - \theta||^2$
نسبت به 
$\phi'$
صفر خواهد بود
).
(10 نمره)

\item
اگر مراحل پرسش قبل را به درستی طی کرده باشید، در جواب خود به یک عبارت حاوی مشتق مرتبه دوم $\nabla^2 \Loss$ (یا همان ماتریس 
\lr{Hessian}
)
می‌رسید. محاسبه این عبارت چه تفاوتی با مشتق مرتبه دوم موجود در رابطه 
\ref{eq:3}
دارد؟ استفاده از این تابع
$\Alg$
پیشنهادی چه مزیتی نسبت به MAML دارد؟
(10 نمره)

\item
به عنوان جمع‌بندی، الگوریتمی که متا-یادگیر در هر اپیزود طی می‌کند را به صورت گام گام شرح دهید.
(5 نمره)

\end{enumerate}

\textbf{پاسخ}

\begin{enumerate}
\item

\begin{subequations}
	\begin{alignat}{2}
		\frac{d}{d\phi'} \Loss(\phi', S) + \frac{\lambda}{2}||\phi' - \theta||^2 = \nabla_{\phi'} \Loss(\phi', S) |_{\phi' = \phi} - \lambda (\phi'-\theta) |_{\phi' = \phi} = 0 \\ 
		\Rightarrow \phi = \theta - \frac{1}{\lambda} \nabla_\phi \Loss (\phi, S) \\
		\Rightarrow \frac{d}{d\theta} \phi = I - \frac{1}{\lambda} \nabla^2_\phi \Loss (\phi, S) \times \frac{d\phi}{d\theta} \\ 
		\Rightarrow \frac{d\phi}{d\theta} = 
		(I +‌ 
		\frac{1}{\lambda} \nabla^2_\phi \Loss (\phi, S)
		)^{-1} \label{eq:51}
	\end{alignat}
\end{subequations}

\item
مشتق مرتبه دوم به دست آمده در الگوریتم MAML به صورت 
$\nabla^2_\theta \Loss(\theta, S)$
می‌باشد این در حالیست که در روش معرفی شده با محاسبه
$\nabla^2_\phi \Loss(\phi, S)$
مواجه می‌شویم. این بدان معناست که مشتق دوم مورد نظر، کافیست در نقطه بهینه حاصل از حل دقیق بهینه‌سازی
\ref{eq:4}
نوشته شود و به مسیری که در گام‌های محاسبه \ref{eq:4}
طی شده است، هیچ وابستگی وجود ندارد. 
توجه کنید که 
$\theta$
همان نقطه شروع بهینه‌سازی است در حالی که 
$\phi$
نقطه نهایی بهینه‌سازی محسوب می‌شود.
لذا در حل 
\ref{eq:4}
کافیست تا گرادیان 
$\theta$
و
$\phi$
را قطع کنیم، بهینه‌سازی 
\ref{eq:4}
را حل کرده و گرادیان مورد نیاز برای آپدیت 
$\theta$
را با کمک روابط 
\ref{eq:2}
و
\ref{eq:51}
به دست آوریم. این درحالیست که در رویکرد MAML (مخصوصاً‌ زمانی که بیش از یک گام بهینه‌سازی در حلقه داخلی بر می‌داریم)، لازم است تا کل گراف محاسباتی و کل وزن‌های محاسبه شده در میان مسیر را نگه داری کنیم تا بتوانیم مشتق‌های مرتبه دو را محاسبه کنیم. 

\item
\begin{itemize}
\item
یک وظیفه (Task) به صورت 
$\mathcal{T} \in D_{meta-train}$
نمونه برداری می‌کنیم که شامل داده‌های پشتیبان (Support)
$S$
و پرسمان (Query)
$Q$
می‌باشد.
\item
با در دست داشتن داده‌های $S$، بهینه‌سازی \ref{eq:4} 
را با روش‌های مرسوم بهینه‌سازی انجام می‌دهیم و حاصل را $\phi$ می‌نامیم.
\item
طبق رابطه 
\ref{eq:51}
مشتق 
$\phi$
نسبت به 
$\theta$
را محاسبه می‌کنیم.
\item
با کمک داده‌های 
$Q$،
عبارت 
$\nabla_{\phi} \Loss (\phi, Q) |_{\phi = \Alg(\theta, S)} $
را محاسبه می‌کنیم.
\item
از ضرب دو رابطه محاسبه شده در دو مورد اخیر، 
$\nabla_{\theta} \Loss (\Alg(\theta, S), Q)$
را محاسبه کرده و با کمک این گرادیان متا-پارامتر‌های 
$\theta$
را آپدیت می‌کنیم.
\end{itemize}

\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% problem 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\problem{(نظری) روش‌های مبتنی بر یادگیری متریک
(55 نمره)
}
روش‌های یادگیری متریک یکی دیگر از روش‌هایی هستند که در درس به عنوان یکی از اعضای خانواده متا-یادگیری با آن‌ها آشنا شدید. در این روش‌ها هدف آن است که یک شبکه استخراج ویژگی مثل
$f_\theta(x)$
یاد گرفته شود تا داده‌ها با برچسب یکسان را در فضای نمایش مخفی در کنار یکدیگر تصویر کند. پارامترهای 
$\theta$
متا-پارامترهای مدل در نظر گرفته شده و در طول متا-یادگیری آموزش داده می‌شوند. از آنجایی که 
$f_\theta(x)$
صرفاً یک فضای نمایشی 
\LTRfootnote{Representation Space}
 فراهم می‌کند، برای کامل کردن شبکه نیاز به یک دسته‌بند (یادگیر پایه
\LTRfootnote{Base-Learner}
) پارامتریک یا نان-پارامتریک داریم که روی این فضای نمایشی قرار گرفته، از داده‌های پشتیبان برای آماده‌سازی خود استفاده کرده و با کمک آن‌ها عمل دسته‌بندی نمونه‌های پرسمان را انجام دهد. پارامترهای دسته‌بند معرفی شده را به عنوان پارامترهای سریع می‌شناسند و آن‌ها را با 
$\phi$
نمایش می‌دهند. این پارامترها مختص هر وظیفه به دست آمده و برای وظیفه بعدی تغییر می‌کنند.

در این روش‌ها یکی از تصمیمات مهم در زمینه طراحی الگوریتم انتخاب مناسب همین دسته‌بند می‌باشد. از جمله انتخاب‌های موجود برای این خانواده، انتخاب روش  
\lr{Nearest Neighbour}
می‌باشد. همچنین روش دیگری که در مقاله 
\href{https://arxiv.org/abs/1703.05175}{ProtoNet}
 معرفی شد استفاده از دسته‌بندهای مبتنی بر پروتوتایپ دسته‌ها (با میانگین گیری از داده‌های موجود در مجموعه پشتیبان از هر کلاس) می‌باشد.  در مقاله
\lr{\href{https://arxiv.org/pdf/1805.08136}{Bertinetto 2018}}
به بررسی دو دسته‌بند رایج در یادگیری ماشین (\lr{Logistic Regression, Ridge Regression}) و نحوه استفاده موثر آن در مسئله متا-یادگیری پرداخته شده است. با مطالعه مقاله و راهنمایی های داده‌ شده در زیر،‌ به سوالات پاسخ دهید:

\begin{enumerate}
	\item
	توضیح دهید که در نگاه اول، استفاده از این دسته‌بندها چه مشکلی می‌تواند برای فرایند متا-آموزش 
	\LTRfootnote{Meta-Training}
	ایجاد کند؟ چرا استفاده از رویکردهای پروتوتایپی یا KNN این مشکل را ایجاد نمی‌کند؟ (راهنمایی: پاسخ این مورد غیر مرتبط با پرسش قبل نیست) (10 نمره)

	\item
	توضیح دهید که در مقاله معرفی شده، چگونه مشکل معرفی شده را حل می‌کند؟ تفاوت رویکردی که برای
	 \lr{Ridge Regression}
	  و 
	  \lr{Logistic Regression}
	  به کار گرفته می‌شود را توضیح دهید. (5 نمره)
	
	\item
	دو ماتریس
	$X \in {\mathbb{R}^{n \times d}}$
به عنوان داده‌های پشتیبان تعبیه شده در فضای نمایش 	و 
	$Y \in {\mathbb{R}^{n \times l}}$
	به عنوان برچسب‌های One-hot همان داده‌ها 	را در نظر بگیرید که n تعداد داده‌ها و d اندازه بردار باز‌نمایی هر داده و l تعداد برچسب‌های موجود در دسته می‌باشد. ثابت کنید که دو رابطه زیر در صورتی که
	$\lambda  > 0$
	باشد، با هم برابر می‌باشند و نحوه استفاده آن در دسته‌بند 
	\lr{Ridge Regression}
	 را توضیح دهید : (10 نمره)
	$$
	{\left( {{X^T}X + \lambda I} \right)^{ - 1}}{X^T}Y = {X^T}{\left( {X{X^T} + \lambda I} \right)^{ - 1}}Y
	$$
	
	\item
	توضیح دهید که برای انجام متا-یادگیری استفاده از کدام یک از دو رابطه بالا بهتر می‌باشد و چرا؟ (5 نمره)
	
	\item
	در مقاله معرفی شده، برای محاسبه وزن‌های دسته‌بند
	\lr{Logistic Regression}
	از بهینه‌سازی با روش 
	\lr{Newton}
استفاده شده است. دلیل این امر را بیان کنید و همچنین در مورد خود
	\lr{Newton's Method}
	تحقیق کنید و رابطه به روزرسانی و نحوه بدست آوردن این رابطه را بنویسید. (10 نمره)
	
	\item
تعاریف زیر را در نظر بگیرید:

$$
\begin{array}{l}
	{A_t} = diag({q_t})\\
	q_t^{\left( i \right)} = \sigma \left( {\omega _t^T{x^{\left( i \right)}}} \right)\left( {1 - \sigma \left( {\omega _t^T{x^{\left( i \right)}}} \right)} \right)\\
	B_t^{\left( i \right)} = \sigma \left( {\omega _t^T{x^{\left( i \right)}}} \right) - {y^{\left( i \right)}}
\end{array}
$$
که
$A \in {\mathbb{R}^{n \times n}}$
یک ماتریس قطری
و
$B \in {\mathbb{R}^n}$
می‌باشد. 

با اعمال
\lr{Newton's Method}
روی تابع هزینه این دسته‌بند، به رابطه به‌روزرسانی زیر برسید (15 نمره) :

$$
{\omega _{t + 1}} = {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}{X^T}\left( {{A_t}X{\omega _t} - {B_t}} \right)
$$

(رابطه فوق مشابه رابطه 7 مقاله می‌باشد با این تفاوت که به نظر می‌رسد روابط موجود در مقاله در برخی جزئیات از نظر Notation ایراد دارند.)

\end{enumerate}

\textbf{پاسخ:}

\begin{enumerate}
	\item
دو دسته بند ذکر شده، دسته‌بندهایی پارامتریک هستند و برای آن که پارامترهای آن‌ها محاسبه شود، نیاز است تا یک دستگاه بهینه‌سازی حل شود. یکی از روش‌های حل دستگاه، استفاده از رویکردهای iterative و استفاده مستقیم از رویکرد 
\lr{Gradient Decent}
<<<<<<< HEAD
 است. بدی استفاده از این نوع Solver آن است که مراحل انجام شده در رویکرد iterative قابلیت محاسبه دقیق را ندارند و این باعث به مشکل خوردن متا-یادگیری می‌شود. به عبارت دقیق‌تر، چون روش‌های Iterative نیازمند گام‌های به نسبت زیادی برای همگرایی به جواب مناسبی هستند و ما در هر به روزرسانی نیازمند نگه‌داری تمام گراف محاسباتی از ابتدا تا انتها هستیم،‌ این مورد یک محدودیتی روی تعداد گام‌های به‌روزرسانی Iterative ایجاد می‌کند و باعث می‌شود جواب دسته‌بند دقیق نباشد. این در حالیست که با استفاده از KNN، به راحتی می‌توان وزن‌های 
=======
 است. بدی استفاده از این نوع Solver آن است که به دلیل حجم بسیار بالای محاسبات، مراحل انجام شده در رویکرد iterative قابلیت عبور گرادیان را ندارند و این باعث به مشکل خوردن متا-یادگیری می‌شود. به عبارت دقیق‌تر، فرض کنید که نمونه‌های پشتیبان را از شبکه استخراج ویژگی عبور داده‌اید و آن‌ها را در فضای نمایشی تعبیه کرده‌اید. سپس با یک رویکرد iterative بهینه‌سازی مربوط به 
 \lr{Ridge Regression}
  را انجام داده و وزن‌های دسته‌بند را به دست می‌آورید. مشکلی که وجود دارد آن است که به دلیل بروز محاسبات سنگین و نیاز به نگه‌داری کل گراف محاسباتی در حافظه، نمی‌توان گرادیان Meta-Loss را از وزن‌های به دست آمده عبور داد و از طریق آن شبکه استخراج ویژگی و پارامترهای 
$\theta$
را آپدیت کرد. این در حالیست که با استفاده از KNN، به راحتی می‌توان وزن‌های 
>>>>>>> a347078bc7b47a0ca7028f5e91e6b20a5617cbbf
$\theta$
را آپدیت کرد چرا که دسته‌بند مستقیماً با خود نمونه‌های هر کلاس کار می‌کند. با استفاده از این رویکرد می‌توان گرادیان را از نمونه‌های موجود هر کلاس عبور داد و از این طریق چینش نمونه‌های یک کلاس را طوری تنظیم کرد که نمونه‌های یک کلاس در فضای نمایش نزدیک یک دیگر بیفتند. رویکرد مشابهی در مورد دسته‌بند پروتوتایپی وجود دارد چرا که عملیات میانگین‌گیری روی نمونه‌های یک کلاس مشکلی برای عبور مسیر گرادیان ایجاد نمی‌کند و با آپدیت کردن 
$\theta$
می‌توان نمونه‌ها را طوری در فضا تعبیه کرد که نمونه‌های مربوط به یک کلاس خاص در نزدیکی پروتوتایپ کلاس خودشان قرار بگیرند.
	\item
	این مقاله برای حل مشکل
	 \lr{Ridge Regression}
	، به جای حل iterative آن، یک جواب Closed-form به عنوان وزن‌های بهینه معرفی می‌کند. این جواب بسته به راحتی قابلیت عبور گرادیان به لایه‌های عقبی را فراهم می‌کند.
	
	از سویی برای دسته‌بند
	 \lr{Logistic Regression}
	 ، از رویکرد iterative خاصی استفاده می‌کند و همزمان نشان می‌دهد که این روش به‌روزرسانی همگرایی سریع‌تری به نسبت روش‌های iterative معمولی دارد. رویکرد مورد استفاده 
	\lr{Newton's Method}
	نام دارد.
	
	\item
	باتوجه به اینکه ماتریس $Y$ در هردو طرف مساوی از سمت راست در معادله ضرب شده است،‌ پس تنها کافی است که اثبات کنیم:
	$$
	{\left( {{X^T}X + \lambda I} \right)^{ - 1}}{X^T} = {X^T}{\left( {X{X^T} + \lambda I} \right)^{ - 1}}
	$$
	برای شروع اثبات در رابطه زیر را در نظر بگیرید:
	$$
	\lambda {X^T} = \lambda {X^T}
	$$
	
	ماتریس همانی را برای یک سمت از رابطه مساوی بالا از سمت چپ ماتریس 
	${X^T}$
	و یک بار از سمت راست ماتریس،‌ ضرب می‌کنیم:
	$$
	\lambda {I_d}{X^T} = \lambda {X^T}{I_n}
	$$
	حال عبارت
	${X^T}X{X^T}$
	را به دو سمت مساوی اضافه می‌کنیم.
	$$
	{X^T}X{X^T} + \lambda {I_d}{X^T} = {X^T}X{X^T} + \lambda {X^T}{I_n}
	$$
	با فاکتورگیری داریم:
	$$
	\left( {{X^T}X + \lambda {I_d}} \right){X^T} = {X^T}\left( {X{X^T} + \lambda {I_n}} \right)
	$$
	حال اگر در دو طرف تساوی، عبارت
	${\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}$
	را از چپ و عبارت
	${\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}}$
	را از سمت راست ضرب کنیم داریم:
	$$
	{\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}\left( {{X^T}X + \lambda {I_d}} \right){X^T}{\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}} = {\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}{X^T}\left( {X{X^T} + \lambda {I_n}} \right){\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}}
	$$
	با ساده‌سازی داریم:
	$$
	{X^T}{\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}} = {\left( {{X^T}X + \lambda {I_d}} \right)^{ - 1}}{X^T}
	$$
	
	که مطلوب سوال می‌باشد. 
	
		این نکته لازم به ذکر می‌باشد که ماتریس‌هایی که معکوس آن را در اثبات بالا استفاده کردیم هردو ماتریس‌های مثبت ‌معین می‌باشند و بنابراین حتما معکوس‌پذیر می‌باشند.
	
	رابطه معرفی شده، همان جواب Closed-Form برای دسته‌بند 
	\lr{Ridge Regression}
	است و همانطور که مشاهده می‌شود، در محاسبه این وزن‌ها تنها از ضرب ماتریسی و معکوس گیری استفاده شده است که این‌ اپراتورها قابلیت عبور گرادیان از خود را فراهم می‌کنند.
	
\item
	
	برای انجام متا-یادگیری استفاده از رابطه
	${X^T}{\left( {X{X^T} + \lambda {I_n}} \right)^{ - 1}}$
	بهینه‌تر می‌باشد. چون در این رابطه نیاز به محاسبه معکوس یک ماتریس با ابعاد
	$n \times n$
	داریم ولی در حالت دیگر نیاز به محاسبه معکوس ماتریسی به ابعاد
	$d \times d$
	می‌باشد که مقدار $d$ که بیانگر ابعاد بازنمایی در شبکه عصبی می‌باشد که به مراتب خیلی بزرگتر از تعداد نمونه‌ها در مسئله‌های متا-یادگیری می‌باشد چرا که که تعداد نمونه‌های پشتیبان در مسائل few-shot خیلی کم می‌باشد.
	
	\item
	به دلیل محدودیت تعداد به‌روزرسانی پارامترها در حلقه درونی الگوریتم،‌از
	\lr{Newton's Method}
	برای همگرایی سریع‌تر به نسبت گرادیان گیری ساده استفاده شده است.
	در
	\lr{Newton's Method}
	علاوه بر گرادیان،‌ اطلاعات مشتق دوم نیز استفاده می‌شود. توجه کنید که در تابع هزینه‌های محدب (از جمله همین 
	\lr{Logistic Regression}
	)
	استفاده از این رویکرد می‌تواند خیلی سریع ما را به نقطه بهینه همگرا کند.
	در این روش با نوشتن بسط Taylor برای تابع هزینه 
	$f$
	حول یک نقطه داریم:
	$$
	f\left( {x + t} \right) = f\left( x \right) + f'\left( x \right)t + \frac{{f''\left( x \right){t^2}}}{2}
	$$
	
	در رابطه بالا برای کمینه کردن مقدار تابع، نسبت به پارامتر $t$ که جهت به‌روزرسانی و حرکت می‌باشد مشتق میگیریم که جهت بهینه به‌روزرسانی را پیدا کنیم:
	$$
	\frac{{dy}}{{dx}}\left( {f\left( x \right) + f'\left( x \right)t + \frac{{f''\left( x \right){t^2}}}{2}} \right) = f'\left( x \right) + f''\left( x \right)t = 0
	$$
	$$
	{t^*} =  - \frac{{f'\left( x \right)}}{{f''\left( x \right)}}
	$$

	بنابراین رابطه بهینه‌سازی را می‌توان به صورت زیر نوشت:
	$$ x_{new} = x_{old} - \frac{f'(x_{old})}{f''(x_{old})} = x_{old} - (\nabla^2_x f)^{-1} \nabla_x f$$
	 
		\item
	
	هدف سوال کمینه‌کردن منفی لگاریتم بیشینه درست‌نمایی به همراه یک جمله منظم‌سازی می‌باشد.
	$$
	P\left( {Y|\omega ,X} \right) = \prod\limits_{i = 1}^N {{{\left( {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right)}^{{y^{\left( i \right)}}}}{{\left( {1 - \sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right)}^{1 - {y^{\left( i \right)}}}}}
	$$
	$$
	L =  - \log P\left( {Y|\omega ,X} \right) + \lambda {\left\| \omega  \right\|^2} =  - \sum\limits_{i = 1}^N {\left[ {{y^{\left( i \right)}}\log \left( {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right) + \left( {1 - {y^{\left( i \right)}}} \right)\log \left( {1 - \sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right)} \right]}  + \lambda {\left\| \omega  \right\|^2}
	$$
	
	حال با گرادیان گیری مقادیر گرادیان اول و دوم را حساب می‌کنیم:
	
	$$
	{\nabla _\omega }L = \sum\limits_{i = 1}^N {\left( {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right) - {y^{\left( i \right)}}} \right){x^{{{\left( i \right)}^T}}}}
	$$
	$$
	H = \nabla _\omega ^2L = \sum\limits_{i = 1}^N {\sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)\left( {1 - \sigma \left( {{\omega ^T}{x^{\left( i \right)}}} \right)} \right){x^{{{\left( i \right)}^T}}}{x^{\left( i \right)}}}
	$$
	
	
	حال اگر سیگماهای بالا را به ضرب ماتریسی تبدیل کنیم،‌ طبق رابطه به‌روزرسانی داریم:
	
	$$
	\begin{aligned}
		{\omega _{t + 1}} & = {\omega _t} - {H^{ - 1}}\nabla L\\
		& = {\omega _t} - {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {{X^T}{B_t} + \lambda {\omega _t}} \right)\\
		&‌= {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {\left( {{X^T}{A_t}X + \lambda I} \right){\omega _t} - {X^T}{B_t} - \lambda {\omega _t}} \right)\\
		&‌= {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}\left( {{X^T}{A_t}X{\omega _t} - {X^T}{B_t}} \right)
	\end{aligned}
	$$
	
	$$
	\Rightarrow
	{\omega _{t + 1}} = {\left( {{X^T}{A_t}X + \lambda I} \right)^{ - 1}}{X^T}\left( {{A_t}X{\omega _t} - {B_t}} \right)
	$$
	
\end{enumerate}


\problem{(نظری) استفاده از دسته‌بند SVM در رویکرد یادگیری متریک
(30 نمره)
}

در این سوال قصد داریم مقاله 
\href{https://arxiv.org/abs/1904.03758}{MetaOptNet}
را مورد بررسی قرار دهیم که برای مدت قابل توجهی SOTA
\LTRfootnote{State-of-the-Art}
 در زمینه یادگیری با تعداد نمونه کم 
 \LTRfootnote{Few-Shot Learning}
 به شمار می‌رفت. این مقاله شباهت بسیار زیادی به مقاله معرفی شده در پرسش قبل دارد با این تفاوت که قصد دارد به جای دسته‌بندهای معرفی شده، دسته‌بند SVM را به عنوان لایه آخر روی شبکه استخراج ویژگی سوار کند. رویکردهایی که در پرسش قبل برای 
\lr{Ridge Regression}
و
\lr{Logistic Regression}
معرفی شدند را نمی‌توان برای SVM به کار برد. لذا این مقاله به دنبال ارائه روشی است تا این مشکل را برطرف نماید. برای این منظور، رویکردی شبیه به پرسش اول را دنبال می‌کند. با این تفاوت که در پرسش اول کل وزن‌های شبکه 
(اعم از دسته‌بند و
 Backbone
 ) 
در دستگاه بهینه‌سازی قرار می‌گرفتند اما در این سوال دستگاه بهینه‌سازی فقط روی وزن‌های دسته‌بند SVM نوشته می‌شود. برای درک بهتر روش، مقاله مورد نظر را بررسی نموده و به پرسش‌های زیر پاسخ دهید:

\begin{enumerate}
	\item
	توضیح دهید که پارامترهای سریع چگونه به کمک داده‌های پشتیبان و پارامترهای آهسته ساخته می‌شوند و دستگاه بهینه‌سازی معرفی شده در این مقاله که از حل آن پارامترهای سریع ساخته می‌شوند را به همراه دوگان آن به صورت دقیق و با ذکر جزئیات نمادگذاری معرفی کنید. (5 نمره)
	\item
	با مطالعه صفحه 4 این مقاله، توضیح دهید که استفاده از قضایای KKT و 
	\lr{Implicit Function Theorem}
	چه کمکی در راستای محاسبه گرادیان می‌کنند و آپدیت شبکه Backbone با استفاده از چه گرادیانی انجام می‌شود؟ (برای این قسمت اثبات دقیق ریاضی مد نظر نیست و به شرطی که به صورت شفاف کاربرد این دو قضیه و نحوه استفاده آن‌ها را بیان کنید نمره کامل را دریافت می‌کنید) (10 نمره)
	\item
	با مطالعه روابط این مقاله ضمن نوشتن دستگاه بهینه‌سازی مربوطه، توضیح دهید که چگونه می‌توان دسته‌بند
	\lr{Ridge Regression}
	مطرح شده در سوال قبل را ذیل همین رویکرد جای داد. (5 نمره)
	\item
	بعد از به دست‌ آوردن وزن‌های بهینه
	$w$
	برای دسته‌بند SVM یا 
	\lr{Ridge Regression}
	، تابع متا-هزینه به چه صورتی نوشته می‌شود؟ از این تابع هزینه برای به‌روزرسانی کدام پارامترها استفاده می‌شود؟ (از رابطه 12 مقاله کمک بگیرید، ولی جزئیات به دست آوردن آن را به صورت شفاف بیان کنید) (10 نمره)
	
\end{enumerate}

توجه: در ادبیات این مقاله، نمادگذاری رایج متا-یادگیری رعایت نشده است و جای نماد
$\theta$
و
$\phi$
با هم عوض شده است. برای یکسان شدن جواب‌ها، شما از نمادگذاری معرفی شده در پرسش اول استفاده کرده و 
$\theta$ و
$\phi$
را به ترتیب برای متا-پارامترها و پارامترهای مختص وظیفه به کار ببرید.

\textbf{پاسخ}
\begin{enumerate}
	\item
	در این مقاله، برای به دست آوردن پارامترهای سریع، پیشنهاد شده است تا یک دستگاه بهینه‌سازی مطابق با تابع‌هزینه SVM حل شود. در مقاله مورد نظر، رابطه (4) این دستگاه را نشان می‌دهد که در آن 	$w$ ها پارامترهای سریع هستند (لازم است این دستگاه نوشته شود و متغیرهای موجود در آن معرفی شوند). در این رویکرد، پارامترهای آهسته همان وزن‌های شبکه استخراج ویژگی هستند که در این مقاله، بر خلاف نمادگذاری رایج، با 
	$\phi$
	نشان داده شده است. به عبارت دیگر، شبکه استخراج ویژگی یک فضای نمایشی ایجاد می‌کند که دسته‌بند SVM بتواند روی آن قرار گرفته و کلاس‌ها را دسته‌بندی نماید.
	\item
	روابط (4) و (5) مقاله، دستگاه‌های بهینه‌سازی را نشان‌ می‌دهد که مربوط به بهینه‌سازی 
	\lr{Inner Loop}
	می‌باشد. حل این دستگاه‌ها با رویکردهای Iterative شدنی است اما مشکلی که به وجود می‌آید آن است که نمی‌توان به سادگی گرادیان را از مراحل Iterative این دستگاه‌ها به عقب برگرداند تا متا-پارامترها آپدیت شوند.
	
	برای این منظور، به جای آن که گرادیان را از مراحل میانی محاسباتی به صورت عقب گرد عبور دهند، سعی می‌شود تا گرادیان را به صورت مستقیم محاسبه کنند. (پاسخ این سوال شباهت زیادی به پرسش اول دارد) به عبارت دیگر، فرض کنید دستگاه‌های ذکر شده حل شده‌اند و پارامتر‌های سریع نهایی به دست‌آمده‌اند. در این صورت، طبق قضیه KKT می‌توان ادعا کرد که مشتق تابع هزینه دستگاه در نقطه بهینه صفر است. از سوی دیگر، اگر از قضیه مشتق ضمنی استفاده شود، می‌توان گرادیان پارامتر‌های سریع نسبت به متغیرهای نهان فضای نمایش و سپس نسبت به متا-پارامترهای مدل را محاسبه کرد. (رابطه (8) مقاله)
	
	\item
	اگر 
	\lr{Ridge Regression}
	را به صورت یک دستگاه بهینه‌سازی بنویسیم، می‌توان حتی علی‌رغم حل Iterative آن، از رویکرد معرفی شده در این سوال استفاده کرد و محاسبه گرادیان‌ها را ممکن ساخت. (رابطه 11 مقاله شرح داده شود).
	
	\item
با فرض این که پارامترهای سریع 
$w$
در مراحل قبلی محاسبه شده‌اند، از تابع هزینه 
\lr{log-likelihood}
در کنار پارامتر قابل یادگیری 
$\gamma$
به عنوان Temperature استفاده می‌شود:

$$\Loss(D^{test}, \theta, \phi, \lambda) = - \sum_{(x,y) \in D^{test}} log p(Y=y|x) = - \sum_{(x,y) log \in D^{test}} softmax (\gamma w f_{\theta}(x) ) $$

$$ = - \sum_{(x,y) \in D^{test}} log \frac{exp (\gamma w_y f_{\theta}(x))}{\sum_k exp (\gamma w_k f_{\theta}(x))} = \sum_{(x,y) \in D^{test}} (-\gamma w_y f_{\theta}(x) + log \sum_k \gamma exp (w_k f_{\theta}(x)))$$
	
از رابطه ذکر شده برای آپدیت متا-پارامترها ($\theta$) استفاده می‌شود. اما باید توجه داشت که روابط فوق علاوه بر وابستگی مستقیم، از طریق 
$w$
نیز به 
$\theta$
وابستگی دارند. لذا در محاسبه مشتق‌های جزئی، رابطه محاسبه شده در رابطه (8) مقاله مورد استفاده واقع می‌شود.

\end{enumerate}


\problem{(نظری) تنظیم توزیع برای یادگیری چند‌‌نمونه‌ای (15 نمره)}
یکی از ریسک‌های احتمالی در یادگیری چندنمونه‌ای احتمال بیش برازش 
\LTRfootnote{Overfitting}
بر روی دادگان کم‌تعداد آموزشی است. در این
\href{https://arxiv.org/abs/2101.06395}{مقاله}
روشی پیشنهاد شده است تا به کمک استخراج مشخصات آماری کلاس‌های حاضر در متا-آموزش بتوان توزیع دادگان کلاس‌های حاضر در متا-ارزیابی را تنظیم کرد. این مقاله را به دقت خوانده و به سوالات زیر به طور کامل پاسخ دهید:

\begin{enumerate}

\item
از آنجایی که ممکن است توزیع دادگان هر کلاس حاضر در متا-آموزش گاوسی نباشد و دارای مقداری کشیدگی باشد؛ در نظر گرفتن این توزیع‌ها به عنوان توزیع گاوسی و استخراج میانگین و کواریانس از آن‌ها می‌تواند اشتباه باشد. توضیح دهید این مقاله چه روشی را برای حل مشکل کشیدگی توزیع دادگان متا-آموزش اتخاد کرده است و چگونه این روش موجب حل مشکل کشیدگی توزیع می‌شود؟(5 نمره)


\textbf{پاسخ}

\begin{figure}[H]

\includegraphics[scale=0.6]{images/S4-1.png} 
\centering
\end{figure}

\item
پس از استخراج میانگین و کواریانس کلاس‌های حاضر در متا-آموزش، مدل ارائه شده اقدام به تنظیم توزیع دادگان حاضر در متا-ارزیابی می‌کند. به صورت کامل و با نوشتن روابط ریاضی مربوطه بیان کنید این تنظیم توزیع به چه صورت انجام می‌پذیرد و وجود کلاس‌های مشابه در متا-آموزش به کلاس منظور در متا-ارزیابی چه کمکی به تنظیم توزیع می‌کند؟ (5 نمره)

\textbf{پاسخ}

\begin{figure}[H]
\includegraphics[scale=0.5]{images/S4-2-1.png} 
\centering
\includegraphics[scale=0.5]{images/S4-2-2.png} 
\centering
\end{figure}
همچنین برای توضیح بیشتر فرض کنید در هنگام متاست تکلیف ما جدا کردن کلاس روباه از کلاغ  در تنظیمات نمونه کم باشد. در صورتی که ما در متاآموزش کلاس های گرگ و کبوتر را داشته باشیم نمونه های کلاس های گرگ و کبوتر به ترتیب میتوانند به کلاس های روباه و کلاغ به علت شباهت کلاس ها کمک کنند و مانع از آورفیت شدن شبکه بر روی تعداد کم داده ها شوند.

\item
در تنظیماتی که در هنگام متا-ارزیابی از هر کلاس بیش از یک نمونه آموزش داشته باشیم این مدل به جای میانگین‌گیری از نمونه‌ها، برای هر کدام از 
\lr{k}
نمونه آموزش اقدام به تنظیم توزیع جداگانه می‌کند. توضیح دهید تنظیم توزیع جداگانه چه مزیتی نسبت به میانگین گیری نمونه‌ها و سپس یک تنظیم توزیع دارد؟(5 نمره)

\textbf{پاسخ}

\begin{figure}[H]
\includegraphics[scale=0.6]{images/S4-3-1.png} 
\centering
\end{figure}
به علاوه در صورتی که توزیع دادگان کلاس حاضر در متاتست یک توزیع چند قله ای باشد، استفاده از یک نمونه نمی تواند مدل خوبی از آن توزیع چند قله ای ارائه دهد. در حالی که استفاده از چند نمونه این مشکل را حل می کند.

\end{enumerate}

\problem{(عملی) یادگیری چندنمونه‌ای از طریق یادگیری متریک (25 نمره)}
در این سوال قصد داریم تا مدل یادگیرنده
شبکه
\href{https://arxiv.org/abs/1703.05175}{\lr{Prototypical}}
را مورد پیاده‌سازی و بررسی قرار دهیم. به این منظور هر دو زیر مجموعه‌های آموزش و تست دادگان
\lr{CIFAR100}
را دریافت کرده و سپس آن‌ها را به یکدیگر الحاق نمایید. 
سپس این دادگان را به سه زیر مجموعه
متا-آموزش، متا-اعتبارسنجی
\LTRfootnote{Meta-Validation}
 و متا-ارزیابی تقسیم کنید. به این صورت که دادگان آموزش شامل دادگان ۷۰ کلاس، دادگان اعتبارسنجی شامل ۲۰ کلاس و دادگان  کلاس تست شامل ۱۰ دیگر باشند.
در گام بعدی بایستی یک 
\lr{Sampler}
پیاده‌سازی کنید که با گرفتن پارامترهای
\lr{Way}
و
\lr{Shot}
بتواند دادگان
اتکا و پرسمان برای یک وظیفه را تولید کنند ( در واقع این ماژول با هر فراخوانی دو مجموعه داده به اندازه
$Way * Shot$
برای اتکا و پرسمان خروجی میدهد). این ماژول در واقع هر بار یک اپیزود را تولید میکند.
در طی آزمایش‌های زیر از ماژول
\lr{ProtoNetBack}
که در فایل‌های پیوستی قرار داده شده است به عنوان شبکه Backbone استخراج ویژگی استفاده کنید و در جلوی آن دو لایه تمام متصل
\LTRfootnote{Fully Connected}
 با اندازه دلخواه قرار دهید.

\begin{enumerate}


\item
دسته‌بند را با تنظیمات
\lr{8-shot, 10-way }
آموزش دهید و سپس دقت مدل را بر روی دادگان متا-ارزیابی گزارش دهید.
انتظار می‌رود دقت در این بخش بیشتر از ۵۱ درصد باشد.

\item
به ازای هر یک از تنظیمات
$shot \in \{1, 2, 4, 8, 16\}$
و
\lr{10-way}
برای متا-آموزش و متا-ارزیابی
آزمایش بالا را تکرار کرده و نمودار دقت متا-ارزیابی بر حسب
\lr{shot}
را رسم نمایید.

\item
حال به ازای هر یک از تنظیمات
$way \in \{2, 4, 8, 16, 32\}$
و
\lr{5-shot}
برای متا-آموزش
آزمایش را تکرار کرده و نمودار دقت متا-ارزیابی بر حسب
\lr{way}
را رسم نمایید.
(دقت کنید که در هنگام متا-ارزیابی از تنظیمات
\lr{5-shot, 10-way}
استفاده نمایید)


\item
حال در هنگام متا-آموزش با تنظیمات
\lr{10-shot, 10-way}
دسته‌بند را آموزش دهید.
در هنگام متا-ارزیابی اما متا-ارزیابی را به ازای هر یک از تنظیمات
$shot \in \{1, 5,10, 15, 20\} $
انجام دهید و نمودار دقت آن را بر حسب 
\lr{shot}
رسم نمایید.

\end{enumerate}




\problem{(عملی) متا-یادگیری براساس بهینه‌سازی (50 نمره)}
در این سوال قصد داریم تا مدل معروف دسته متا-یادگیری براساس بهینه‌سازی،‌MAML،‌ را پیاده‌سازی نماییم. مقاله مرتبط با این کار،
\href{https://arxiv.org/pdf/1703.03400}{این مقاله}
می‌باشد. در Notebook داده شده تمام پارامترهای مسئله و مراحل حل به صورت گام به گام تشریح شده است.
سوال از دو بخش اصلی تشکیل شده است که در بخش اول به دلیل کاهش هزینه آموزش بخش عمده شبکه به صورت pretrained شده در اختیار شما قرار داده شده است و شما تنها روی بخش مشخص شده شبکه فرایند متا-یادگیری را انجام خواهید داد. در بخش اول قرار است تاثیر تعداد گام‌های به‌روزرسانی مدل در حلقه داخلی الگوریتم، مورد بررسی قرار گیرد. از شما خواسته شده است که به ازای مقادیر 1 تا 3 این مورد را انجام دهید و نتیجه هر حالت را مقایسه و گزارش کنید. در بخش دوم نیز از شما خواسته شده است که حال با یک گام به‌روزرسانی حلقه داخلی‌، کل ساختار مدل (مدل متا-یادگیری بخش اول + ساختار مدل pretrained داده شده) را به صورت متاپارامتر در نظر بگیرید و متا-یادگیری را روی آن انجام دهید. در نهایت نتایج بدست آمده از هردو بخش را تحلیل و گزارش نمایید.







\end{document}
