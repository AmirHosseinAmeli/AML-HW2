{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CE-40959: Advanced Machine Learning\n",
        "## HW2 - Optimization-based Meta Learning (100 points)\n",
        "\n",
        "#### Name: \n",
        "#### Student No.: "
      ],
      "metadata": {
        "id": "Oma2ZStyqpQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, you are going to implement a optimization-based meta learner using the `Omniglot` dataset.\n",
        "\n",
        "Please write your code in specified sections and do not change anything else. If you have a question regarding this homework, please ask it on the Quera.\n",
        "\n",
        "Also, it is recommended to use Google Colab to do this homework. You can connect to your drive using the code below:"
      ],
      "metadata": {
        "id": "zATL8bguriGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSsY1Jw7pwZc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required libraries"
      ],
      "metadata": {
        "id": "fZJ_Hv8Uqoil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "2NGBSeo0L6Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "xabeci_XPcU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Meta-Learning literature and in the meta-training phase, you are given some batches which consist of `support` and `query` sets. you train your model in a way that by using a support set you could predict query set labels correctly.\n",
        "\n",
        "The pioneer of this branch is Model-Agnostic Meta-Learning(MAML). \n",
        "\n",
        "First, we should build the dataset in this way that each batch returns N*(k+k') images. `k` is the number of support images per class and `k'` is the number of query images per class in a batch.\n",
        "\n",
        "The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1623 different handwritten characters from 50 different alphabets. Each of the 1623 characters was drawn online via Amazon's Mechanical Turk by 20 different people.\n",
        "\n",
        "Train and test dataset contains 964 and 659 classes, respectively. Torchvision-based Omniglot dataset is ordered and every 20 images in a row belong to one class."
      ],
      "metadata": {
        "id": "mNHVKqRMM2oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta learning parameters.\n",
        "\n",
        "N = 5\n",
        "support_size = 1\n",
        "query_size = 15\n",
        "meta_inner_lr = 0.4\n",
        "meta_outer_lr = 0.001"
      ],
      "metadata": {
        "id": "ZU6nY6ZPDJla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset (5 points)"
      ],
      "metadata": {
        "id": "Z8bS05XnPe7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(28),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = True, transform = transform)\n",
        "test_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = False, transform = transform)\n",
        "\n",
        "train_labels = np.repeat(np.arange(964), 20)\n",
        "test_labels = np.repeat(np.arange(659), 20)"
      ],
      "metadata": {
        "id": "pMXx6_Py9AhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build a dataloader, we should have a class that yields indexes of selected data in the dataset for every iteration and pass it to the `batch_sampler` attribute of dataloader.\n",
        "\n",
        "Complete below code based on this pseudocode:\n",
        "\n",
        "\n",
        "1.   select `N` classes randomly from all classes\n",
        "2.   select `support_size + query_size` images from each classes independently and randomly\n",
        "3.   shuffle dataset indexes, but don't forget to put query indexes at the last of the list"
      ],
      "metadata": {
        "id": "oWK0vksv4nVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchSampler(object):\n",
        "    '''\n",
        "    BatchSampler: yield a batch of indexes at each iteration.\n",
        "    __len__ returns the number of episodes per epoch (same as 'self.iterations').\n",
        "    '''\n",
        "\n",
        "    def __init__(self, labels, classes_per_it, num_samples, iterations, batch_size):\n",
        "        '''\n",
        "        Initialize the BatchSampler object\n",
        "        Args:\n",
        "        - labels: array of labels of dataset.\n",
        "        - classes_per_it: number of random classes for each iteration\n",
        "        - num_samples: number of samples for each iteration for each class\n",
        "        - iterations: number of iterations (episodes) per epoch\n",
        "        - batch_size: number of batches per iteration\n",
        "        '''\n",
        "        super(BatchSampler, self).__init__()\n",
        "        self.labels = labels\n",
        "        self.classes_per_it = classes_per_it\n",
        "        self.sample_per_class = num_samples\n",
        "        self.iterations = iterations\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        '''\n",
        "        yield a batch of indexes\n",
        "        '''\n",
        "\n",
        "        for it in range(self.iterations):\n",
        "            total_batch_indexes = np.array([])\n",
        "\n",
        "            #################################################################################\n",
        "            #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n",
        "            #################################################################################\n",
        "            # feel free to add/edit initialization part of sampler.\n",
        "            #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #################################################################################\n",
        "            #                                   THE END                                     #\n",
        "            #################################################################################\n",
        "\n",
        "            yield total_batch_indexes.astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.iterations"
      ],
      "metadata": {
        "id": "yODgabjHEY9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 5000\n",
        "batch_size = 32\n",
        "\n",
        "train_sampler = BatchSampler(labels=train_labels, classes_per_it=N,\n",
        "                              num_samples=K, iterations=iterations,\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "test_sampler = BatchSampler(labels=test_labels, classes_per_it=N,\n",
        "                              num_samples=K, iterations=iterations,\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler)"
      ],
      "metadata": {
        "id": "vkaRutIUPF4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model (45 points)"
      ],
      "metadata": {
        "id": "xnvAPmPmPh92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Build our model. the whole model is `ProtoNet` feature extractor which is used in [Prototypical Network paper](https://arxiv.org/abs/1703.05175) but due to the lack of enough computational resources for first part of question, we give you some part of the network as pretraining and only you will do meta-training on the last layer of the network."
      ],
      "metadata": {
        "id": "52JCi9o-M2sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels, momentum=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "class Feature_extractor(nn.Module):\n",
        "    '''\n",
        "    source: https://github.com/jakesnell/prototypical-networks/blob/f0c48808e496989d01db59f86d4449d7aee9ab0c/protonets/models/few_shot.py#L62-L84\n",
        "    '''\n",
        "    def __init__(self, x_dim=1, hid_dim=64):\n",
        "        super(Feature_extractor, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(x_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)"
      ],
      "metadata": {
        "id": "eY3brHqVVXdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = Feature_extractor()\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "model.load_state_dict(torch.load('./pretrained_model.pt', map_location=device))"
      ],
      "metadata": {
        "id": "QEucQ0e669mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be specific, you are going to get the features of each image via the feature extraction network and give the output of that as input to your meta-learner. at the end of initialization, you should have initialized your network parameters and have saved them on the given ParameterList for future forward passes.\n",
        "\n",
        "The `Learner` class is a module that initializes your meta-parameters based on your given config as input. the format of config is arbitrary and you should prepare required parameters for initializing your submodules. do a quick look at the modules of meta-network to implement your Learner class.\n",
        "\n",
        "At forwarding pass, you give your input and two optional attributes.\n",
        "\n",
        "1.   **vars**: the default value of this attribute is None and it means that meta-learner will use its own parameters for forwarding pass, but you can give your desired parameters for computing output\n",
        "2.   **bn_training**: if True, batch normalization layers show the same behavior as training time.\n",
        "\n",
        "\n",
        "In the `zero_grad` method, you are going to set the gradient of given parameters as attribute or class parameters (self.vars) to zero.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uVFRmUfM7UN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Learner(nn.Module):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Learner, self).__init__()\n",
        "\n",
        "        # this dict contains all tensors needed to be optimized\n",
        "        self.vars = nn.ParameterList()\n",
        "        # running_mean and running_var\n",
        "        self.vars_bn = nn.ParameterList()\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
        "        #################################################################################\n",
        "        # initialize your meta-network parameters based on given config.\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x, vars=None, bn_training=True):\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
        "        #################################################################################\n",
        "        # compute output of input with given parameters or class parameters\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "    def zero_grad(self, vars=None):\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n",
        "        #################################################################################\n",
        "        # set gradient of given parameters as attribute or class parameters to zero\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.vars"
      ],
      "metadata": {
        "id": "S7QX9qUnBLSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now at the `Meta` module, you implement your meta-learner module. you give your all support and query data to your module and the model will update your `Learner` parameters based on MAML-loss.\n",
        "to clarify, you pass your support data to `Learner` and then calculate the loss on them and update your parameters and then continue to update your parameters based on the given number of inner-loop updates and finally calculate the loss on query data and update `Learner` parameters"
      ],
      "metadata": {
        "id": "JHnhkgpMPk-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Meta(nn.Module):\n",
        "    def __init__(self, *args, ***kwargs):\n",
        "\n",
        "        super(Meta, self).__init__()\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (5 points)                   #\n",
        "        #################################################################################\n",
        "        # initialize your meta-learner\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (15 points)                   #\n",
        "        #################################################################################\n",
        "        # meta-train your parameters.\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b9ebAUChOy68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Feature Extractor"
      ],
      "metadata": {
        "id": "qgbrX1ykMYre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your Meta-network which you are going to initialize your Learner based on it for first part of question is as follows:\n",
        "\n",
        "\n",
        "1.   **Conv2d layer**: in_channels=64, out_channels:64, kernel_size=3, stride=1, padding=1\n",
        "2.   **BatchNorm2D layer**: out_channels=64\n",
        "3.   **ReLU activation**\n",
        "4.   **Max Pooling layer**: kernel_size = 2, stride = 2\n",
        "5.   **Flatten layer**\n",
        "6.   **Linear layer**: in_features=64, out_features=N (number of classes in meta-learning)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QC9bnPrdDI-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta-train **three** different networks with three different inner loop updates=[1, 2, 3]. after some reasonable epochs, plot accuracy of meta-test phase based on inner loop update parameter on each network."
      ],
      "metadata": {
        "id": "5aP7sZNrE2Jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train (25 points)"
      ],
      "metadata": {
        "id": "si_-sVXgbYbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#################################################################################\n",
        "#                  COMPLETE THE FOLLOWING SECTION (25 points)                   #\n",
        "#################################################################################\n",
        "# Define your config and initialize model and parameters\n",
        "# prepare your data as input to your model.\n",
        "# train meta-network\n",
        "# get acurracy of model in meta-test phase\n",
        "#################################################################################\n",
        "lr = None\n",
        "model = None\n",
        "epochs = None\n",
        "criterion = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n"
      ],
      "metadata": {
        "id": "vwyVINHPbc5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot (2.5 points)"
      ],
      "metadata": {
        "id": "E5X-lOSBN15I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot accuracy of meta-test phase based on inner loop update parameter."
      ],
      "metadata": {
        "id": "5hDTwQqmNnX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4FDQZ0WoNCOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without Feature Extractor"
      ],
      "metadata": {
        "id": "ZTILlHKIIGfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train (10 points)"
      ],
      "metadata": {
        "id": "NTDVBPWqOeNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now also add feature extractor network to your meta-network and repeat the same procedure like above cells just for inner loop update = 1.\n"
      ],
      "metadata": {
        "id": "LyYmPMOSN66S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#################################################################################\n",
        "#                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
        "#################################################################################\n",
        "# Define your config and initialize model and parameters\n",
        "# prepare your data as input to your model.\n",
        "# train meta-network\n",
        "# get acurracy of model in meta-test phase\n",
        "#################################################################################\n",
        "lr = None\n",
        "model = None\n",
        "epochs = None\n",
        "criterion = None\n",
        "inner_loop_update = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n"
      ],
      "metadata": {
        "id": "4ALu1EEDQ0RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report (2.5 points)"
      ],
      "metadata": {
        "id": "6qSBg8MQO9aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report accuracy of meta-test phase."
      ],
      "metadata": {
        "id": "ylzdpCPfOZSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_tnYxuh9Oa8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare and explain Results"
      ],
      "metadata": {
        "id": "QVX1qagbRGvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "UOKygCh_Rhkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fb2aUT1ARivE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}